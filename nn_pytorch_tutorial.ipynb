{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn_pytorch_tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferdianjovan/colab/blob/master/nn_pytorch_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wdlOZya1cptl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "182a4a5d-41eb-4b84-f4a1-d32bd511bd64"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "l5UwR_WWeAtQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = torch.tensor(([2, 9], [1, 5], [3, 6]), dtype=torch.float)   # 3 x 2 tensor\n",
        "y = torch.tensor(([92], [100], [89]), dtype=torch.float)        # 3 x 1 tensor\n",
        "xPredicted = torch.tensor(([4, 8]), dtype=torch.float)          # 1 x 2 tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yokcwCieewI5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# torch.max(tensor, axis_to_apply_max) returns the maximum value and the index of the value.\n",
        "X_max, _ = torch.max(X, 0)\n",
        "xPredicted_max, _ = torch.max(xPredicted, 0)\n",
        "\n",
        "X = torch.div(X, X_max)                                         # normalisation\n",
        "xPredicted = torch.div(xPredicted, xPredicted_max)              # normalisation\n",
        "y = y / 100                                                     # max test score is 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7lbl3lIMfhmP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Neural_Network(nn.Module):\n",
        "    \n",
        "    def __init__(self, inputSize=2, outputSize=1, hiddenSize=3):\n",
        "        super(Neural_Network, self).__init__()\n",
        "        # parameters\n",
        "        # TODO: parameters can be parameterized instead of declaring them here\n",
        "        self.inputSize = inputSize\n",
        "        self.outputSize = outputSize\n",
        "        self.hiddenSize = hiddenSize\n",
        "        \n",
        "        # weights, since we build nn from scratch.\n",
        "        # we need one that stores the parameters from input layer, and one that\n",
        "        # stores the parameters from output layer\n",
        "        self.W1 = torch.randn(self.inputSize, self.hiddenSize)    # 2 x 3 tensor\n",
        "        self.W2 = torch.randn(self.hiddenSize, self.outputSize)   # 3 x 1 tensor\n",
        "    \n",
        "    def forward(self, X):\n",
        "        self.z = torch.matmul(X, self.W1)                         # 3 x 3 \".dot\" does not broadcast in PyTorch\n",
        "        self.z2 = self.sigmoid(self.z)                            # activation function\n",
        "        self.z3 = torch.matmul(self.z2, self.W2)\n",
        "        o = self.sigmoid(self.z3)                                 # final activation function\n",
        "        return o\n",
        "        \n",
        "    def sigmoid(self, s):\n",
        "        return 1 / (1 + torch.exp(-s))\n",
        "      \n",
        "    def sigmoidPrime(self, s):\n",
        "        # derivative of sigmoid\n",
        "        return s * (1 - s)\n",
        "      \n",
        "    def backward(self, X, y, o):\n",
        "        self.o_error = y - o                                       # error in output\n",
        "        self.o_delta = self.o_error * self.sigmoidPrime(o)\n",
        "        self.z2_error = torch.matmul(self.o_delta, torch.t(self.W2))\n",
        "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.z2)\n",
        "        self.W1 += torch.matmul(torch.t(X), self.z2_delta)\n",
        "        self.W2 += torch.matmul(torch.t(self.z2), self.o_delta)\n",
        "    \n",
        "    def train(self, X, y):\n",
        "        # forward + backward pass for training\n",
        "        o = self.forward(X)\n",
        "        self.backward(X, y, o)\n",
        "        \n",
        "    def saveWeights(self, model):\n",
        "        # we will use the PyTorch internal storage functions\n",
        "        torch.save(model.state_dict(), 'NN')\n",
        "        # you can reload model with all the weights and so forth with:\n",
        "        # model.load_state_dict(torch.load('NN'))\n",
        "        \n",
        "    def predict(self):\n",
        "        print('Predicted data based on trained weights: ')\n",
        "        print('Input (scaled): \\n' + str(xPredicted))\n",
        "        print('Output: \\n' + str(self.forward(xPredicted)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5-ZUgv7JnO2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16901
        },
        "outputId": "0a13748e-b385-47b6-fdbf-3e192c179544"
      },
      "cell_type": "code",
      "source": [
        "NN = Neural_Network()\n",
        "for i in range(1000):                                               # trains NN 1000 times\n",
        "    print('#' + str(i) + ' Loss: ' + str(torch.mean((y - NN(X))**2).detach().numpy()))\n",
        "    NN.train(X, y)\n",
        "NN.saveWeights(NN)\n",
        "NN.predict()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#0 Loss: 0.19999798\n",
            "#1 Loss: 0.109270684\n",
            "#2 Loss: 0.065681085\n",
            "#3 Loss: 0.04424435\n",
            "#4 Loss: 0.03244332\n",
            "#5 Loss: 0.0252617\n",
            "#6 Loss: 0.020545183\n",
            "#7 Loss: 0.017264666\n",
            "#8 Loss: 0.014880102\n",
            "#9 Loss: 0.013085697\n",
            "#10 Loss: 0.011697234\n",
            "#11 Loss: 0.010598101\n",
            "#12 Loss: 0.009711299\n",
            "#13 Loss: 0.008984234\n",
            "#14 Loss: 0.008379875\n",
            "#15 Loss: 0.007871528\n",
            "#16 Loss: 0.007439453\n",
            "#17 Loss: 0.00706886\n",
            "#18 Loss: 0.0067484076\n",
            "#19 Loss: 0.0064692893\n",
            "#20 Loss: 0.0062246085\n",
            "#21 Loss: 0.006008838\n",
            "#22 Loss: 0.00581756\n",
            "#23 Loss: 0.005647158\n",
            "#24 Loss: 0.0054946872\n",
            "#25 Loss: 0.0053576916\n",
            "#26 Loss: 0.005234158\n",
            "#27 Loss: 0.005122362\n",
            "#28 Loss: 0.0050208573\n",
            "#29 Loss: 0.0049284236\n",
            "#30 Loss: 0.0048440215\n",
            "#31 Loss: 0.0047667455\n",
            "#32 Loss: 0.0046958276\n",
            "#33 Loss: 0.0046305847\n",
            "#34 Loss: 0.004570441\n",
            "#35 Loss: 0.0045148777\n",
            "#36 Loss: 0.0044634594\n",
            "#37 Loss: 0.004415777\n",
            "#38 Loss: 0.004371491\n",
            "#39 Loss: 0.0043302886\n",
            "#40 Loss: 0.004291902\n",
            "#41 Loss: 0.0042560813\n",
            "#42 Loss: 0.004222605\n",
            "#43 Loss: 0.0041912817\n",
            "#44 Loss: 0.0041619376\n",
            "#45 Loss: 0.004134412\n",
            "#46 Loss: 0.004108558\n",
            "#47 Loss: 0.0040842467\n",
            "#48 Loss: 0.0040613706\n",
            "#49 Loss: 0.004039812\n",
            "#50 Loss: 0.004019486\n",
            "#51 Loss: 0.004000291\n",
            "#52 Loss: 0.0039821626\n",
            "#53 Loss: 0.0039650127\n",
            "#54 Loss: 0.0039487756\n",
            "#55 Loss: 0.0039334013\n",
            "#56 Loss: 0.0039188247\n",
            "#57 Loss: 0.0039049836\n",
            "#58 Loss: 0.0038918506\n",
            "#59 Loss: 0.0038793732\n",
            "#60 Loss: 0.0038675023\n",
            "#61 Loss: 0.0038562089\n",
            "#62 Loss: 0.003845459\n",
            "#63 Loss: 0.0038352145\n",
            "#64 Loss: 0.0038254466\n",
            "#65 Loss: 0.003816129\n",
            "#66 Loss: 0.0038072364\n",
            "#67 Loss: 0.0037987444\n",
            "#68 Loss: 0.0037906237\n",
            "#69 Loss: 0.0037828635\n",
            "#70 Loss: 0.0037754402\n",
            "#71 Loss: 0.0037683288\n",
            "#72 Loss: 0.003761527\n",
            "#73 Loss: 0.0037550007\n",
            "#74 Loss: 0.0037487491\n",
            "#75 Loss: 0.0037427582\n",
            "#76 Loss: 0.0037370038\n",
            "#77 Loss: 0.003731475\n",
            "#78 Loss: 0.0037261732\n",
            "#79 Loss: 0.0037210754\n",
            "#80 Loss: 0.0037161775\n",
            "#81 Loss: 0.0037114657\n",
            "#82 Loss: 0.0037069358\n",
            "#83 Loss: 0.0037025686\n",
            "#84 Loss: 0.003698364\n",
            "#85 Loss: 0.003694317\n",
            "#86 Loss: 0.0036904134\n",
            "#87 Loss: 0.003686651\n",
            "#88 Loss: 0.0036830225\n",
            "#89 Loss: 0.0036795188\n",
            "#90 Loss: 0.0036761435\n",
            "#91 Loss: 0.003672878\n",
            "#92 Loss: 0.0036697232\n",
            "#93 Loss: 0.0036666777\n",
            "#94 Loss: 0.0036637296\n",
            "#95 Loss: 0.0036608847\n",
            "#96 Loss: 0.0036581287\n",
            "#97 Loss: 0.0036554597\n",
            "#98 Loss: 0.0036528774\n",
            "#99 Loss: 0.0036503794\n",
            "#100 Loss: 0.0036479551\n",
            "#101 Loss: 0.0036456005\n",
            "#102 Loss: 0.003643322\n",
            "#103 Loss: 0.0036411185\n",
            "#104 Loss: 0.0036389716\n",
            "#105 Loss: 0.0036368931\n",
            "#106 Loss: 0.0036348721\n",
            "#107 Loss: 0.0036329078\n",
            "#108 Loss: 0.0036310002\n",
            "#109 Loss: 0.0036291508\n",
            "#110 Loss: 0.0036273496\n",
            "#111 Loss: 0.0036255915\n",
            "#112 Loss: 0.0036238905\n",
            "#113 Loss: 0.0036222292\n",
            "#114 Loss: 0.0036206169\n",
            "#115 Loss: 0.0036190432\n",
            "#116 Loss: 0.0036175074\n",
            "#117 Loss: 0.0036160164\n",
            "#118 Loss: 0.0036145586\n",
            "#119 Loss: 0.003613135\n",
            "#120 Loss: 0.0036117511\n",
            "#121 Loss: 0.0036103956\n",
            "#122 Loss: 0.0036090754\n",
            "#123 Loss: 0.0036077898\n",
            "#124 Loss: 0.0036065218\n",
            "#125 Loss: 0.0036052938\n",
            "#126 Loss: 0.003604088\n",
            "#127 Loss: 0.003602909\n",
            "#128 Loss: 0.0036017606\n",
            "#129 Loss: 0.0036006381\n",
            "#130 Loss: 0.0035995313\n",
            "#131 Loss: 0.0035984514\n",
            "#132 Loss: 0.0035973939\n",
            "#133 Loss: 0.0035963573\n",
            "#134 Loss: 0.0035953394\n",
            "#135 Loss: 0.0035943447\n",
            "#136 Loss: 0.0035933706\n",
            "#137 Loss: 0.00359241\n",
            "#138 Loss: 0.003591473\n",
            "#139 Loss: 0.0035905456\n",
            "#140 Loss: 0.0035896453\n",
            "#141 Loss: 0.0035887512\n",
            "#142 Loss: 0.003587878\n",
            "#143 Loss: 0.0035870168\n",
            "#144 Loss: 0.0035861693\n",
            "#145 Loss: 0.0035853463\n",
            "#146 Loss: 0.0035845179\n",
            "#147 Loss: 0.00358372\n",
            "#148 Loss: 0.003582923\n",
            "#149 Loss: 0.0035821444\n",
            "#150 Loss: 0.003581373\n",
            "#151 Loss: 0.0035806198\n",
            "#152 Loss: 0.0035798745\n",
            "#153 Loss: 0.0035791416\n",
            "#154 Loss: 0.0035784168\n",
            "#155 Loss: 0.0035776987\n",
            "#156 Loss: 0.0035769942\n",
            "#157 Loss: 0.0035763008\n",
            "#158 Loss: 0.0035756112\n",
            "#159 Loss: 0.0035749294\n",
            "#160 Loss: 0.003574264\n",
            "#161 Loss: 0.0035735965\n",
            "#162 Loss: 0.0035729446\n",
            "#163 Loss: 0.0035723\n",
            "#164 Loss: 0.0035716596\n",
            "#165 Loss: 0.0035710267\n",
            "#166 Loss: 0.0035704048\n",
            "#167 Loss: 0.0035697843\n",
            "#168 Loss: 0.0035691664\n",
            "#169 Loss: 0.0035685624\n",
            "#170 Loss: 0.003567965\n",
            "#171 Loss: 0.00356737\n",
            "#172 Loss: 0.0035667857\n",
            "#173 Loss: 0.0035661943\n",
            "#174 Loss: 0.0035656188\n",
            "#175 Loss: 0.003565047\n",
            "#176 Loss: 0.003564474\n",
            "#177 Loss: 0.0035639144\n",
            "#178 Loss: 0.0035633566\n",
            "#179 Loss: 0.0035628031\n",
            "#180 Loss: 0.0035622518\n",
            "#181 Loss: 0.0035617042\n",
            "#182 Loss: 0.0035611645\n",
            "#183 Loss: 0.0035606287\n",
            "#184 Loss: 0.0035600949\n",
            "#185 Loss: 0.0035595652\n",
            "#186 Loss: 0.0035590364\n",
            "#187 Loss: 0.0035585128\n",
            "#188 Loss: 0.0035579894\n",
            "#189 Loss: 0.0035574764\n",
            "#190 Loss: 0.00355696\n",
            "#191 Loss: 0.0035564539\n",
            "#192 Loss: 0.003555945\n",
            "#193 Loss: 0.0035554387\n",
            "#194 Loss: 0.0035549353\n",
            "#195 Loss: 0.003554437\n",
            "#196 Loss: 0.0035539337\n",
            "#197 Loss: 0.0035534452\n",
            "#198 Loss: 0.0035529502\n",
            "#199 Loss: 0.0035524555\n",
            "#200 Loss: 0.003551974\n",
            "#201 Loss: 0.0035514857\n",
            "#202 Loss: 0.0035510052\n",
            "#203 Loss: 0.0035505185\n",
            "#204 Loss: 0.003550039\n",
            "#205 Loss: 0.003549559\n",
            "#206 Loss: 0.003549087\n",
            "#207 Loss: 0.0035486093\n",
            "#208 Loss: 0.0035481371\n",
            "#209 Loss: 0.0035476657\n",
            "#210 Loss: 0.0035471972\n",
            "#211 Loss: 0.0035467315\n",
            "#212 Loss: 0.0035462603\n",
            "#213 Loss: 0.0035457935\n",
            "#214 Loss: 0.0035453273\n",
            "#215 Loss: 0.0035448668\n",
            "#216 Loss: 0.003544402\n",
            "#217 Loss: 0.0035439457\n",
            "#218 Loss: 0.003543488\n",
            "#219 Loss: 0.0035430277\n",
            "#220 Loss: 0.0035425704\n",
            "#221 Loss: 0.0035421134\n",
            "#222 Loss: 0.0035416605\n",
            "#223 Loss: 0.003541204\n",
            "#224 Loss: 0.0035407543\n",
            "#225 Loss: 0.0035402973\n",
            "#226 Loss: 0.003539846\n",
            "#227 Loss: 0.0035393953\n",
            "#228 Loss: 0.0035389487\n",
            "#229 Loss: 0.0035384959\n",
            "#230 Loss: 0.003538049\n",
            "#231 Loss: 0.0035376057\n",
            "#232 Loss: 0.003537155\n",
            "#233 Loss: 0.003536705\n",
            "#234 Loss: 0.0035362642\n",
            "#235 Loss: 0.003535821\n",
            "#236 Loss: 0.003535373\n",
            "#237 Loss: 0.003534926\n",
            "#238 Loss: 0.0035344854\n",
            "#239 Loss: 0.0035340444\n",
            "#240 Loss: 0.0035336015\n",
            "#241 Loss: 0.003533154\n",
            "#242 Loss: 0.0035327151\n",
            "#243 Loss: 0.0035322756\n",
            "#244 Loss: 0.003531831\n",
            "#245 Loss: 0.0035313896\n",
            "#246 Loss: 0.0035309463\n",
            "#247 Loss: 0.0035305044\n",
            "#248 Loss: 0.0035300665\n",
            "#249 Loss: 0.00352963\n",
            "#250 Loss: 0.0035291836\n",
            "#251 Loss: 0.0035287458\n",
            "#252 Loss: 0.0035283093\n",
            "#253 Loss: 0.003527876\n",
            "#254 Loss: 0.0035274345\n",
            "#255 Loss: 0.0035269947\n",
            "#256 Loss: 0.003526558\n",
            "#257 Loss: 0.0035261128\n",
            "#258 Loss: 0.0035256774\n",
            "#259 Loss: 0.0035252413\n",
            "#260 Loss: 0.0035248\n",
            "#261 Loss: 0.0035243642\n",
            "#262 Loss: 0.0035239246\n",
            "#263 Loss: 0.0035234888\n",
            "#264 Loss: 0.0035230487\n",
            "#265 Loss: 0.0035226156\n",
            "#266 Loss: 0.0035221707\n",
            "#267 Loss: 0.0035217365\n",
            "#268 Loss: 0.0035213002\n",
            "#269 Loss: 0.0035208638\n",
            "#270 Loss: 0.0035204198\n",
            "#271 Loss: 0.003519987\n",
            "#272 Loss: 0.0035195511\n",
            "#273 Loss: 0.0035191115\n",
            "#274 Loss: 0.003518671\n",
            "#275 Loss: 0.0035182338\n",
            "#276 Loss: 0.0035177926\n",
            "#277 Loss: 0.003517357\n",
            "#278 Loss: 0.0035169206\n",
            "#279 Loss: 0.003516481\n",
            "#280 Loss: 0.0035160426\n",
            "#281 Loss: 0.003515602\n",
            "#282 Loss: 0.0035151646\n",
            "#283 Loss: 0.0035147264\n",
            "#284 Loss: 0.0035142833\n",
            "#285 Loss: 0.0035138447\n",
            "#286 Loss: 0.003513407\n",
            "#287 Loss: 0.0035129685\n",
            "#288 Loss: 0.0035125285\n",
            "#289 Loss: 0.0035120882\n",
            "#290 Loss: 0.003511646\n",
            "#291 Loss: 0.0035112023\n",
            "#292 Loss: 0.0035107657\n",
            "#293 Loss: 0.0035103273\n",
            "#294 Loss: 0.0035098882\n",
            "#295 Loss: 0.0035094384\n",
            "#296 Loss: 0.0035090048\n",
            "#297 Loss: 0.003508554\n",
            "#298 Loss: 0.0035081152\n",
            "#299 Loss: 0.0035076737\n",
            "#300 Loss: 0.003507232\n",
            "#301 Loss: 0.0035067901\n",
            "#302 Loss: 0.003506345\n",
            "#303 Loss: 0.003505905\n",
            "#304 Loss: 0.0035054588\n",
            "#305 Loss: 0.0035050164\n",
            "#306 Loss: 0.0035045724\n",
            "#307 Loss: 0.0035041273\n",
            "#308 Loss: 0.0035036877\n",
            "#309 Loss: 0.003503237\n",
            "#310 Loss: 0.0035027943\n",
            "#311 Loss: 0.0035023503\n",
            "#312 Loss: 0.0035019044\n",
            "#313 Loss: 0.0035014544\n",
            "#314 Loss: 0.0035010146\n",
            "#315 Loss: 0.0035005633\n",
            "#316 Loss: 0.0035001163\n",
            "#317 Loss: 0.0034996727\n",
            "#318 Loss: 0.0034992255\n",
            "#319 Loss: 0.003498773\n",
            "#320 Loss: 0.00349833\n",
            "#321 Loss: 0.003497877\n",
            "#322 Loss: 0.0034974304\n",
            "#323 Loss: 0.0034969815\n",
            "#324 Loss: 0.0034965316\n",
            "#325 Loss: 0.0034960818\n",
            "#326 Loss: 0.0034956273\n",
            "#327 Loss: 0.0034951803\n",
            "#328 Loss: 0.0034947302\n",
            "#329 Loss: 0.0034942788\n",
            "#330 Loss: 0.003493825\n",
            "#331 Loss: 0.003493373\n",
            "#332 Loss: 0.003492921\n",
            "#333 Loss: 0.0034924701\n",
            "#334 Loss: 0.0034920163\n",
            "#335 Loss: 0.003491565\n",
            "#336 Loss: 0.003491108\n",
            "#337 Loss: 0.0034906555\n",
            "#338 Loss: 0.003490199\n",
            "#339 Loss: 0.003489742\n",
            "#340 Loss: 0.0034892906\n",
            "#341 Loss: 0.0034888356\n",
            "#342 Loss: 0.0034883777\n",
            "#343 Loss: 0.0034879206\n",
            "#344 Loss: 0.0034874703\n",
            "#345 Loss: 0.0034870058\n",
            "#346 Loss: 0.003486551\n",
            "#347 Loss: 0.0034860938\n",
            "#348 Loss: 0.0034856342\n",
            "#349 Loss: 0.0034851758\n",
            "#350 Loss: 0.0034847155\n",
            "#351 Loss: 0.0034842615\n",
            "#352 Loss: 0.0034837995\n",
            "#353 Loss: 0.0034833376\n",
            "#354 Loss: 0.0034828745\n",
            "#355 Loss: 0.0034824193\n",
            "#356 Loss: 0.003481955\n",
            "#357 Loss: 0.0034814968\n",
            "#358 Loss: 0.0034810274\n",
            "#359 Loss: 0.0034805704\n",
            "#360 Loss: 0.0034801047\n",
            "#361 Loss: 0.0034796428\n",
            "#362 Loss: 0.0034791755\n",
            "#363 Loss: 0.0034787115\n",
            "#364 Loss: 0.0034782458\n",
            "#365 Loss: 0.0034777801\n",
            "#366 Loss: 0.0034773191\n",
            "#367 Loss: 0.0034768516\n",
            "#368 Loss: 0.0034763862\n",
            "#369 Loss: 0.0034759182\n",
            "#370 Loss: 0.00347545\n",
            "#371 Loss: 0.00347498\n",
            "#372 Loss: 0.0034745156\n",
            "#373 Loss: 0.0034740474\n",
            "#374 Loss: 0.0034735787\n",
            "#375 Loss: 0.0034731103\n",
            "#376 Loss: 0.0034726404\n",
            "#377 Loss: 0.0034721706\n",
            "#378 Loss: 0.0034716951\n",
            "#379 Loss: 0.0034712248\n",
            "#380 Loss: 0.0034707536\n",
            "#381 Loss: 0.0034702823\n",
            "#382 Loss: 0.00346981\n",
            "#383 Loss: 0.0034693375\n",
            "#384 Loss: 0.0034688627\n",
            "#385 Loss: 0.0034683913\n",
            "#386 Loss: 0.0034679174\n",
            "#387 Loss: 0.0034674394\n",
            "#388 Loss: 0.0034669668\n",
            "#389 Loss: 0.0034664935\n",
            "#390 Loss: 0.0034660164\n",
            "#391 Loss: 0.0034655363\n",
            "#392 Loss: 0.003465063\n",
            "#393 Loss: 0.0034645842\n",
            "#394 Loss: 0.0034641053\n",
            "#395 Loss: 0.003463626\n",
            "#396 Loss: 0.0034631507\n",
            "#397 Loss: 0.0034626704\n",
            "#398 Loss: 0.003462185\n",
            "#399 Loss: 0.00346171\n",
            "#400 Loss: 0.0034612308\n",
            "#401 Loss: 0.0034607507\n",
            "#402 Loss: 0.0034602687\n",
            "#403 Loss: 0.003459784\n",
            "#404 Loss: 0.0034593008\n",
            "#405 Loss: 0.0034588191\n",
            "#406 Loss: 0.0034583353\n",
            "#407 Loss: 0.0034578473\n",
            "#408 Loss: 0.0034573665\n",
            "#409 Loss: 0.0034568862\n",
            "#410 Loss: 0.0034563977\n",
            "#411 Loss: 0.0034559125\n",
            "#412 Loss: 0.0034554217\n",
            "#413 Loss: 0.0034549367\n",
            "#414 Loss: 0.003454453\n",
            "#415 Loss: 0.0034539637\n",
            "#416 Loss: 0.0034534794\n",
            "#417 Loss: 0.0034529886\n",
            "#418 Loss: 0.0034524994\n",
            "#419 Loss: 0.0034520086\n",
            "#420 Loss: 0.0034515194\n",
            "#421 Loss: 0.0034510235\n",
            "#422 Loss: 0.003450539\n",
            "#423 Loss: 0.003450048\n",
            "#424 Loss: 0.0034495525\n",
            "#425 Loss: 0.003449063\n",
            "#426 Loss: 0.0034485676\n",
            "#427 Loss: 0.0034480721\n",
            "#428 Loss: 0.0034475836\n",
            "#429 Loss: 0.0034470884\n",
            "#430 Loss: 0.0034465957\n",
            "#431 Loss: 0.0034460954\n",
            "#432 Loss: 0.0034455957\n",
            "#433 Loss: 0.0034451047\n",
            "#434 Loss: 0.0034446071\n",
            "#435 Loss: 0.0034441135\n",
            "#436 Loss: 0.0034436097\n",
            "#437 Loss: 0.0034431114\n",
            "#438 Loss: 0.0034426132\n",
            "#439 Loss: 0.003442118\n",
            "#440 Loss: 0.003441615\n",
            "#441 Loss: 0.0034411203\n",
            "#442 Loss: 0.003440615\n",
            "#443 Loss: 0.0034401158\n",
            "#444 Loss: 0.0034396087\n",
            "#445 Loss: 0.0034391098\n",
            "#446 Loss: 0.003438608\n",
            "#447 Loss: 0.0034381028\n",
            "#448 Loss: 0.0034375985\n",
            "#449 Loss: 0.0034370925\n",
            "#450 Loss: 0.0034365917\n",
            "#451 Loss: 0.0034360818\n",
            "#452 Loss: 0.0034355794\n",
            "#453 Loss: 0.003435069\n",
            "#454 Loss: 0.003434565\n",
            "#455 Loss: 0.0034340573\n",
            "#456 Loss: 0.0034335488\n",
            "#457 Loss: 0.0034330396\n",
            "#458 Loss: 0.0034325316\n",
            "#459 Loss: 0.003432019\n",
            "#460 Loss: 0.0034315141\n",
            "#461 Loss: 0.0034310005\n",
            "#462 Loss: 0.0034304904\n",
            "#463 Loss: 0.0034299798\n",
            "#464 Loss: 0.0034294666\n",
            "#465 Loss: 0.0034289553\n",
            "#466 Loss: 0.003428443\n",
            "#467 Loss: 0.0034279265\n",
            "#468 Loss: 0.0034274105\n",
            "#469 Loss: 0.0034269022\n",
            "#470 Loss: 0.003426383\n",
            "#471 Loss: 0.0034258652\n",
            "#472 Loss: 0.0034253516\n",
            "#473 Loss: 0.0034248338\n",
            "#474 Loss: 0.0034243178\n",
            "#475 Loss: 0.0034238023\n",
            "#476 Loss: 0.0034232822\n",
            "#477 Loss: 0.0034227595\n",
            "#478 Loss: 0.0034222417\n",
            "#479 Loss: 0.00342172\n",
            "#480 Loss: 0.0034211997\n",
            "#481 Loss: 0.00342068\n",
            "#482 Loss: 0.003420159\n",
            "#483 Loss: 0.003419632\n",
            "#484 Loss: 0.003419116\n",
            "#485 Loss: 0.003418588\n",
            "#486 Loss: 0.0034180612\n",
            "#487 Loss: 0.0034175382\n",
            "#488 Loss: 0.0034170148\n",
            "#489 Loss: 0.0034164917\n",
            "#490 Loss: 0.003415967\n",
            "#491 Loss: 0.0034154393\n",
            "#492 Loss: 0.0034149115\n",
            "#493 Loss: 0.0034143794\n",
            "#494 Loss: 0.0034138544\n",
            "#495 Loss: 0.0034133268\n",
            "#496 Loss: 0.0034127964\n",
            "#497 Loss: 0.0034122616\n",
            "#498 Loss: 0.0034117363\n",
            "#499 Loss: 0.0034112018\n",
            "#500 Loss: 0.0034106772\n",
            "#501 Loss: 0.0034101398\n",
            "#502 Loss: 0.0034096122\n",
            "#503 Loss: 0.0034090702\n",
            "#504 Loss: 0.003408541\n",
            "#505 Loss: 0.0034080085\n",
            "#506 Loss: 0.0034074734\n",
            "#507 Loss: 0.0034069389\n",
            "#508 Loss: 0.0034064061\n",
            "#509 Loss: 0.0034058646\n",
            "#510 Loss: 0.0034053249\n",
            "#511 Loss: 0.0034047856\n",
            "#512 Loss: 0.0034042513\n",
            "#513 Loss: 0.0034037104\n",
            "#514 Loss: 0.0034031717\n",
            "#515 Loss: 0.0034026334\n",
            "#516 Loss: 0.0034020923\n",
            "#517 Loss: 0.0034015512\n",
            "#518 Loss: 0.003401013\n",
            "#519 Loss: 0.0034004676\n",
            "#520 Loss: 0.0033999218\n",
            "#521 Loss: 0.0033993826\n",
            "#522 Loss: 0.0033988326\n",
            "#523 Loss: 0.003398293\n",
            "#524 Loss: 0.0033977507\n",
            "#525 Loss: 0.003397204\n",
            "#526 Loss: 0.0033966543\n",
            "#527 Loss: 0.0033961078\n",
            "#528 Loss: 0.0033955611\n",
            "#529 Loss: 0.0033950147\n",
            "#530 Loss: 0.0033944577\n",
            "#531 Loss: 0.0033939143\n",
            "#532 Loss: 0.0033933662\n",
            "#533 Loss: 0.0033928156\n",
            "#534 Loss: 0.0033922568\n",
            "#535 Loss: 0.003391709\n",
            "#536 Loss: 0.0033911585\n",
            "#537 Loss: 0.0033906072\n",
            "#538 Loss: 0.0033900545\n",
            "#539 Loss: 0.0033894961\n",
            "#540 Loss: 0.0033889387\n",
            "#541 Loss: 0.0033883853\n",
            "#542 Loss: 0.0033878332\n",
            "#543 Loss: 0.0033872789\n",
            "#544 Loss: 0.003386717\n",
            "#545 Loss: 0.0033861639\n",
            "#546 Loss: 0.0033856023\n",
            "#547 Loss: 0.0033850428\n",
            "#548 Loss: 0.0033844803\n",
            "#549 Loss: 0.0033839245\n",
            "#550 Loss: 0.0033833657\n",
            "#551 Loss: 0.0033828008\n",
            "#552 Loss: 0.0033822397\n",
            "#553 Loss: 0.003381675\n",
            "#554 Loss: 0.003381112\n",
            "#555 Loss: 0.0033805475\n",
            "#556 Loss: 0.0033799878\n",
            "#557 Loss: 0.0033794234\n",
            "#558 Loss: 0.0033788588\n",
            "#559 Loss: 0.00337829\n",
            "#560 Loss: 0.0033777251\n",
            "#561 Loss: 0.0033771563\n",
            "#562 Loss: 0.0033765852\n",
            "#563 Loss: 0.0033760238\n",
            "#564 Loss: 0.0033754555\n",
            "#565 Loss: 0.003374879\n",
            "#566 Loss: 0.0033743104\n",
            "#567 Loss: 0.0033737384\n",
            "#568 Loss: 0.0033731672\n",
            "#569 Loss: 0.0033726\n",
            "#570 Loss: 0.0033720273\n",
            "#571 Loss: 0.003371449\n",
            "#572 Loss: 0.0033708739\n",
            "#573 Loss: 0.0033702943\n",
            "#574 Loss: 0.0033697255\n",
            "#575 Loss: 0.003369145\n",
            "#576 Loss: 0.0033685686\n",
            "#577 Loss: 0.0033679893\n",
            "#578 Loss: 0.0033674163\n",
            "#579 Loss: 0.003366836\n",
            "#580 Loss: 0.00336626\n",
            "#581 Loss: 0.0033656796\n",
            "#582 Loss: 0.003365104\n",
            "#583 Loss: 0.0033645208\n",
            "#584 Loss: 0.0033639378\n",
            "#585 Loss: 0.0033633579\n",
            "#586 Loss: 0.00336277\n",
            "#587 Loss: 0.003362187\n",
            "#588 Loss: 0.0033616044\n",
            "#589 Loss: 0.0033610167\n",
            "#590 Loss: 0.0033604354\n",
            "#591 Loss: 0.0033598458\n",
            "#592 Loss: 0.0033592584\n",
            "#593 Loss: 0.0033586742\n",
            "#594 Loss: 0.003358085\n",
            "#595 Loss: 0.0033574908\n",
            "#596 Loss: 0.00335691\n",
            "#597 Loss: 0.003356316\n",
            "#598 Loss: 0.0033557226\n",
            "#599 Loss: 0.0033551287\n",
            "#600 Loss: 0.00335454\n",
            "#601 Loss: 0.0033539503\n",
            "#602 Loss: 0.003353353\n",
            "#603 Loss: 0.0033527624\n",
            "#604 Loss: 0.0033521673\n",
            "#605 Loss: 0.0033515699\n",
            "#606 Loss: 0.0033509743\n",
            "#607 Loss: 0.0033503755\n",
            "#608 Loss: 0.0033497864\n",
            "#609 Loss: 0.003349182\n",
            "#610 Loss: 0.003348587\n",
            "#611 Loss: 0.003347983\n",
            "#612 Loss: 0.003347382\n",
            "#613 Loss: 0.0033467833\n",
            "#614 Loss: 0.0033461817\n",
            "#615 Loss: 0.0033455815\n",
            "#616 Loss: 0.00334498\n",
            "#617 Loss: 0.003344374\n",
            "#618 Loss: 0.0033437714\n",
            "#619 Loss: 0.0033431638\n",
            "#620 Loss: 0.0033425621\n",
            "#621 Loss: 0.003341956\n",
            "#622 Loss: 0.0033413495\n",
            "#623 Loss: 0.0033407398\n",
            "#624 Loss: 0.0033401286\n",
            "#625 Loss: 0.0033395223\n",
            "#626 Loss: 0.0033389127\n",
            "#627 Loss: 0.0033383043\n",
            "#628 Loss: 0.0033376925\n",
            "#629 Loss: 0.0033370822\n",
            "#630 Loss: 0.0033364678\n",
            "#631 Loss: 0.0033358543\n",
            "#632 Loss: 0.0033352394\n",
            "#633 Loss: 0.0033346277\n",
            "#634 Loss: 0.0033340156\n",
            "#635 Loss: 0.0033333937\n",
            "#636 Loss: 0.0033327797\n",
            "#637 Loss: 0.0033321676\n",
            "#638 Loss: 0.0033315474\n",
            "#639 Loss: 0.0033309225\n",
            "#640 Loss: 0.003330307\n",
            "#641 Loss: 0.0033296912\n",
            "#642 Loss: 0.0033290666\n",
            "#643 Loss: 0.0033284482\n",
            "#644 Loss: 0.0033278288\n",
            "#645 Loss: 0.0033272004\n",
            "#646 Loss: 0.003326582\n",
            "#647 Loss: 0.0033259534\n",
            "#648 Loss: 0.0033253294\n",
            "#649 Loss: 0.0033247017\n",
            "#650 Loss: 0.0033240793\n",
            "#651 Loss: 0.003323451\n",
            "#652 Loss: 0.003322821\n",
            "#653 Loss: 0.003322197\n",
            "#654 Loss: 0.003321563\n",
            "#655 Loss: 0.003320937\n",
            "#656 Loss: 0.0033203047\n",
            "#657 Loss: 0.0033196758\n",
            "#658 Loss: 0.0033190409\n",
            "#659 Loss: 0.0033184076\n",
            "#660 Loss: 0.003317776\n",
            "#661 Loss: 0.0033171398\n",
            "#662 Loss: 0.003316507\n",
            "#663 Loss: 0.0033158734\n",
            "#664 Loss: 0.0033152353\n",
            "#665 Loss: 0.0033145968\n",
            "#666 Loss: 0.0033139617\n",
            "#667 Loss: 0.0033133214\n",
            "#668 Loss: 0.0033126872\n",
            "#669 Loss: 0.0033120494\n",
            "#670 Loss: 0.003311407\n",
            "#671 Loss: 0.0033107616\n",
            "#672 Loss: 0.003310115\n",
            "#673 Loss: 0.003309476\n",
            "#674 Loss: 0.0033088399\n",
            "#675 Loss: 0.0033081903\n",
            "#676 Loss: 0.0033075449\n",
            "#677 Loss: 0.003306899\n",
            "#678 Loss: 0.003306256\n",
            "#679 Loss: 0.0033056026\n",
            "#680 Loss: 0.0033049595\n",
            "#681 Loss: 0.0033043046\n",
            "#682 Loss: 0.003303662\n",
            "#683 Loss: 0.0033030116\n",
            "#684 Loss: 0.0033023588\n",
            "#685 Loss: 0.0033017073\n",
            "#686 Loss: 0.0033010559\n",
            "#687 Loss: 0.0033004011\n",
            "#688 Loss: 0.0032997467\n",
            "#689 Loss: 0.0032990954\n",
            "#690 Loss: 0.0032984416\n",
            "#691 Loss: 0.0032977883\n",
            "#692 Loss: 0.003297123\n",
            "#693 Loss: 0.0032964663\n",
            "#694 Loss: 0.0032958116\n",
            "#695 Loss: 0.003295148\n",
            "#696 Loss: 0.0032944884\n",
            "#697 Loss: 0.0032938283\n",
            "#698 Loss: 0.0032931678\n",
            "#699 Loss: 0.0032925091\n",
            "#700 Loss: 0.0032918418\n",
            "#701 Loss: 0.0032911804\n",
            "#702 Loss: 0.0032905156\n",
            "#703 Loss: 0.003289847\n",
            "#704 Loss: 0.0032891827\n",
            "#705 Loss: 0.0032885177\n",
            "#706 Loss: 0.0032878465\n",
            "#707 Loss: 0.0032871838\n",
            "#708 Loss: 0.0032865189\n",
            "#709 Loss: 0.003285845\n",
            "#710 Loss: 0.0032851696\n",
            "#711 Loss: 0.003284499\n",
            "#712 Loss: 0.0032838273\n",
            "#713 Loss: 0.003283153\n",
            "#714 Loss: 0.003282483\n",
            "#715 Loss: 0.0032818094\n",
            "#716 Loss: 0.003281128\n",
            "#717 Loss: 0.0032804506\n",
            "#718 Loss: 0.0032797775\n",
            "#719 Loss: 0.003279099\n",
            "#720 Loss: 0.003278426\n",
            "#721 Loss: 0.0032777453\n",
            "#722 Loss: 0.0032770622\n",
            "#723 Loss: 0.0032763823\n",
            "#724 Loss: 0.0032756971\n",
            "#725 Loss: 0.0032750203\n",
            "#726 Loss: 0.0032743346\n",
            "#727 Loss: 0.0032736475\n",
            "#728 Loss: 0.003272969\n",
            "#729 Loss: 0.0032722822\n",
            "#730 Loss: 0.0032715958\n",
            "#731 Loss: 0.0032709055\n",
            "#732 Loss: 0.003270217\n",
            "#733 Loss: 0.0032695306\n",
            "#734 Loss: 0.0032688377\n",
            "#735 Loss: 0.003268146\n",
            "#736 Loss: 0.0032674589\n",
            "#737 Loss: 0.0032667692\n",
            "#738 Loss: 0.0032660768\n",
            "#739 Loss: 0.0032653797\n",
            "#740 Loss: 0.0032646877\n",
            "#741 Loss: 0.0032639923\n",
            "#742 Loss: 0.00326329\n",
            "#743 Loss: 0.0032625936\n",
            "#744 Loss: 0.0032618977\n",
            "#745 Loss: 0.0032611992\n",
            "#746 Loss: 0.0032605038\n",
            "#747 Loss: 0.003259801\n",
            "#748 Loss: 0.0032591\n",
            "#749 Loss: 0.0032584\n",
            "#750 Loss: 0.0032576935\n",
            "#751 Loss: 0.003256996\n",
            "#752 Loss: 0.0032562858\n",
            "#753 Loss: 0.0032555864\n",
            "#754 Loss: 0.0032548795\n",
            "#755 Loss: 0.0032541736\n",
            "#756 Loss: 0.0032534653\n",
            "#757 Loss: 0.0032527512\n",
            "#758 Loss: 0.0032520455\n",
            "#759 Loss: 0.0032513335\n",
            "#760 Loss: 0.0032506275\n",
            "#761 Loss: 0.00324992\n",
            "#762 Loss: 0.0032492022\n",
            "#763 Loss: 0.0032484878\n",
            "#764 Loss: 0.0032477751\n",
            "#765 Loss: 0.0032470599\n",
            "#766 Loss: 0.0032463425\n",
            "#767 Loss: 0.003245623\n",
            "#768 Loss: 0.0032449104\n",
            "#769 Loss: 0.0032441914\n",
            "#770 Loss: 0.0032434715\n",
            "#771 Loss: 0.0032427527\n",
            "#772 Loss: 0.00324203\n",
            "#773 Loss: 0.0032413097\n",
            "#774 Loss: 0.003240591\n",
            "#775 Loss: 0.0032398624\n",
            "#776 Loss: 0.0032391364\n",
            "#777 Loss: 0.0032384172\n",
            "#778 Loss: 0.003237688\n",
            "#779 Loss: 0.0032369664\n",
            "#780 Loss: 0.0032362333\n",
            "#781 Loss: 0.0032355015\n",
            "#782 Loss: 0.003234777\n",
            "#783 Loss: 0.0032340467\n",
            "#784 Loss: 0.003233319\n",
            "#785 Loss: 0.003232584\n",
            "#786 Loss: 0.003231852\n",
            "#787 Loss: 0.0032311168\n",
            "#788 Loss: 0.0032303825\n",
            "#789 Loss: 0.0032296467\n",
            "#790 Loss: 0.0032289056\n",
            "#791 Loss: 0.0032281687\n",
            "#792 Loss: 0.0032274304\n",
            "#793 Loss: 0.0032266974\n",
            "#794 Loss: 0.0032259526\n",
            "#795 Loss: 0.0032252166\n",
            "#796 Loss: 0.003224471\n",
            "#797 Loss: 0.0032237293\n",
            "#798 Loss: 0.00322299\n",
            "#799 Loss: 0.0032222467\n",
            "#800 Loss: 0.003221497\n",
            "#801 Loss: 0.003220754\n",
            "#802 Loss: 0.003220003\n",
            "#803 Loss: 0.0032192587\n",
            "#804 Loss: 0.00321851\n",
            "#805 Loss: 0.0032177574\n",
            "#806 Loss: 0.0032170105\n",
            "#807 Loss: 0.003216258\n",
            "#808 Loss: 0.0032155085\n",
            "#809 Loss: 0.003214753\n",
            "#810 Loss: 0.0032140024\n",
            "#811 Loss: 0.0032132482\n",
            "#812 Loss: 0.003212492\n",
            "#813 Loss: 0.003211733\n",
            "#814 Loss: 0.0032109749\n",
            "#815 Loss: 0.003210218\n",
            "#816 Loss: 0.0032094605\n",
            "#817 Loss: 0.0032086924\n",
            "#818 Loss: 0.0032079376\n",
            "#819 Loss: 0.0032071779\n",
            "#820 Loss: 0.0032064083\n",
            "#821 Loss: 0.0032056503\n",
            "#822 Loss: 0.0032048842\n",
            "#823 Loss: 0.0032041196\n",
            "#824 Loss: 0.003203354\n",
            "#825 Loss: 0.0032025834\n",
            "#826 Loss: 0.0032018193\n",
            "#827 Loss: 0.0032010488\n",
            "#828 Loss: 0.0032002758\n",
            "#829 Loss: 0.003199509\n",
            "#830 Loss: 0.0031987354\n",
            "#831 Loss: 0.0031979608\n",
            "#832 Loss: 0.0031971876\n",
            "#833 Loss: 0.003196411\n",
            "#834 Loss: 0.0031956371\n",
            "#835 Loss: 0.0031948576\n",
            "#836 Loss: 0.0031940825\n",
            "#837 Loss: 0.0031933046\n",
            "#838 Loss: 0.0031925302\n",
            "#839 Loss: 0.0031917458\n",
            "#840 Loss: 0.0031909635\n",
            "#841 Loss: 0.0031901828\n",
            "#842 Loss: 0.0031894045\n",
            "#843 Loss: 0.0031886147\n",
            "#844 Loss: 0.0031878324\n",
            "#845 Loss: 0.0031870464\n",
            "#846 Loss: 0.0031862622\n",
            "#847 Loss: 0.00318547\n",
            "#848 Loss: 0.003184682\n",
            "#849 Loss: 0.0031838927\n",
            "#850 Loss: 0.0031831013\n",
            "#851 Loss: 0.0031823106\n",
            "#852 Loss: 0.0031815215\n",
            "#853 Loss: 0.0031807253\n",
            "#854 Loss: 0.0031799304\n",
            "#855 Loss: 0.0031791376\n",
            "#856 Loss: 0.0031783402\n",
            "#857 Loss: 0.0031775471\n",
            "#858 Loss: 0.0031767513\n",
            "#859 Loss: 0.0031759422\n",
            "#860 Loss: 0.0031751476\n",
            "#861 Loss: 0.0031743513\n",
            "#862 Loss: 0.0031735457\n",
            "#863 Loss: 0.0031727431\n",
            "#864 Loss: 0.00317194\n",
            "#865 Loss: 0.0031711368\n",
            "#866 Loss: 0.0031703275\n",
            "#867 Loss: 0.0031695182\n",
            "#868 Loss: 0.003168719\n",
            "#869 Loss: 0.0031679103\n",
            "#870 Loss: 0.0031670972\n",
            "#871 Loss: 0.0031662856\n",
            "#872 Loss: 0.0031654753\n",
            "#873 Loss: 0.0031646676\n",
            "#874 Loss: 0.0031638525\n",
            "#875 Loss: 0.0031630357\n",
            "#876 Loss: 0.0031622264\n",
            "#877 Loss: 0.0031614043\n",
            "#878 Loss: 0.0031605896\n",
            "#879 Loss: 0.0031597742\n",
            "#880 Loss: 0.0031589505\n",
            "#881 Loss: 0.0031581307\n",
            "#882 Loss: 0.003157312\n",
            "#883 Loss: 0.0031564916\n",
            "#884 Loss: 0.0031556666\n",
            "#885 Loss: 0.0031548468\n",
            "#886 Loss: 0.00315402\n",
            "#887 Loss: 0.0031531912\n",
            "#888 Loss: 0.0031523604\n",
            "#889 Loss: 0.0031515353\n",
            "#890 Loss: 0.003150707\n",
            "#891 Loss: 0.0031498792\n",
            "#892 Loss: 0.0031490445\n",
            "#893 Loss: 0.0031482184\n",
            "#894 Loss: 0.0031473862\n",
            "#895 Loss: 0.0031465467\n",
            "#896 Loss: 0.0031457164\n",
            "#897 Loss: 0.0031448808\n",
            "#898 Loss: 0.0031440447\n",
            "#899 Loss: 0.0031432107\n",
            "#900 Loss: 0.0031423673\n",
            "#901 Loss: 0.0031415306\n",
            "#902 Loss: 0.0031406889\n",
            "#903 Loss: 0.0031398442\n",
            "#904 Loss: 0.0031390016\n",
            "#905 Loss: 0.0031381575\n",
            "#906 Loss: 0.0031373147\n",
            "#907 Loss: 0.0031364746\n",
            "#908 Loss: 0.0031356253\n",
            "#909 Loss: 0.0031347747\n",
            "#910 Loss: 0.0031339258\n",
            "#911 Loss: 0.0031330816\n",
            "#912 Loss: 0.003132229\n",
            "#913 Loss: 0.0031313773\n",
            "#914 Loss: 0.003130527\n",
            "#915 Loss: 0.0031296713\n",
            "#916 Loss: 0.0031288152\n",
            "#917 Loss: 0.0031279598\n",
            "#918 Loss: 0.0031271009\n",
            "#919 Loss: 0.0031262476\n",
            "#920 Loss: 0.0031253865\n",
            "#921 Loss: 0.0031245276\n",
            "#922 Loss: 0.0031236624\n",
            "#923 Loss: 0.0031228072\n",
            "#924 Loss: 0.0031219444\n",
            "#925 Loss: 0.0031210824\n",
            "#926 Loss: 0.0031202144\n",
            "#927 Loss: 0.0031193465\n",
            "#928 Loss: 0.0031184815\n",
            "#929 Loss: 0.0031176165\n",
            "#930 Loss: 0.003116742\n",
            "#931 Loss: 0.0031158775\n",
            "#932 Loss: 0.003115003\n",
            "#933 Loss: 0.003114136\n",
            "#934 Loss: 0.0031132577\n",
            "#935 Loss: 0.003112386\n",
            "#936 Loss: 0.0031115103\n",
            "#937 Loss: 0.0031106323\n",
            "#938 Loss: 0.0031097622\n",
            "#939 Loss: 0.0031088814\n",
            "#940 Loss: 0.0031079976\n",
            "#941 Loss: 0.003107121\n",
            "#942 Loss: 0.00310624\n",
            "#943 Loss: 0.0031053617\n",
            "#944 Loss: 0.0031044732\n",
            "#945 Loss: 0.003103594\n",
            "#946 Loss: 0.0031027058\n",
            "#947 Loss: 0.0031018239\n",
            "#948 Loss: 0.0031009342\n",
            "#949 Loss: 0.0031000448\n",
            "#950 Loss: 0.0030991603\n",
            "#951 Loss: 0.003098267\n",
            "#952 Loss: 0.0030973759\n",
            "#953 Loss: 0.0030964853\n",
            "#954 Loss: 0.003095587\n",
            "#955 Loss: 0.0030946946\n",
            "#956 Loss: 0.0030937933\n",
            "#957 Loss: 0.003092901\n",
            "#958 Loss: 0.003092006\n",
            "#959 Loss: 0.003091098\n",
            "#960 Loss: 0.0030902047\n",
            "#961 Loss: 0.0030893013\n",
            "#962 Loss: 0.003088406\n",
            "#963 Loss: 0.0030874975\n",
            "#964 Loss: 0.0030865937\n",
            "#965 Loss: 0.0030856896\n",
            "#966 Loss: 0.0030847846\n",
            "#967 Loss: 0.0030838742\n",
            "#968 Loss: 0.0030829653\n",
            "#969 Loss: 0.0030820563\n",
            "#970 Loss: 0.0030811494\n",
            "#971 Loss: 0.0030802395\n",
            "#972 Loss: 0.0030793224\n",
            "#973 Loss: 0.0030784132\n",
            "#974 Loss: 0.0030774896\n",
            "#975 Loss: 0.0030765831\n",
            "#976 Loss: 0.0030756614\n",
            "#977 Loss: 0.0030747422\n",
            "#978 Loss: 0.0030738246\n",
            "#979 Loss: 0.0030729074\n",
            "#980 Loss: 0.0030719854\n",
            "#981 Loss: 0.0030710641\n",
            "#982 Loss: 0.003070142\n",
            "#983 Loss: 0.0030692194\n",
            "#984 Loss: 0.0030682941\n",
            "#985 Loss: 0.0030673633\n",
            "#986 Loss: 0.003066438\n",
            "#987 Loss: 0.0030655067\n",
            "#988 Loss: 0.0030645777\n",
            "#989 Loss: 0.003063646\n",
            "#990 Loss: 0.0030627223\n",
            "#991 Loss: 0.0030617835\n",
            "#992 Loss: 0.0030608482\n",
            "#993 Loss: 0.0030599132\n",
            "#994 Loss: 0.0030589758\n",
            "#995 Loss: 0.0030580412\n",
            "#996 Loss: 0.0030571024\n",
            "#997 Loss: 0.0030561641\n",
            "#998 Loss: 0.0030552223\n",
            "#999 Loss: 0.0030542805\n",
            "Predicted data based on trained weights: \n",
            "Input (scaled): \n",
            "tensor([0.5000, 1.0000])\n",
            "Output: \n",
            "tensor([0.9435])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0mV0cTZ5owSZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}